{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark training for data engineers\n",
    "## 01. Python development\n",
    "\n",
    "### Goal\n",
    "Setup the environment to work with `pyspark`. The options below describe howto develop locally, in a virtual environment or using Docker.\n",
    "\n",
    "### Process\n",
    "Lets start with a simple requirement file with only `pyspark`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%file requirements.txt\n",
    "pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "jitsejan@dev16:~/itility/pyspark-101$ pip install -r requirements.txt\n",
    "jitsejan@dev16:~/itility/pyspark-101$ pyspark --version\n",
    "Welcome to\n",
    "      ____              __\n",
    "     / __/__  ___ _____/ /__\n",
    "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
    "   /___/ .__/\\_,_/_/ /_/\\_\\   version 2.3.0\n",
    "      /_/\n",
    "\n",
    "Using Scala version 2.11.8, OpenJDK 64-Bit Server VM, 1.8.0_162\n",
    "Branch master\n",
    "Compiled by user sameera on 2018-02-22T19:24:29Z\n",
    "Revision a0d7949896e70f427e7f3942ff340c9484ff0aab\n",
    "Url git@github.com:sameeragarwal/spark.git\n",
    "Type --help for more information.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Virtual environment\n",
    "\n",
    "```bash\n",
    "\n",
    "jitsejan@dev16:~/itility/pyspark-101$ conda create -n pyspark python=2\n",
    "jitsejan@dev16:~/itility/pyspark-101$ source activate pyspark\n",
    "(pyspark) jitsejan@dev16:~/itility/pyspark-101$ pip install -r requirements.txt\n",
    "(pyspark) jitsejan@dev16:~/itility/pyspark-101$ pyspark --version\n",
    "Welcome to\n",
    "      ____              __\n",
    "     / __/__  ___ _____/ /__\n",
    "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
    "   /___/ .__/\\_,_/_/ /_/\\_\\   version 2.3.0\n",
    "      /_/\n",
    "\n",
    "Using Scala version 2.11.8, OpenJDK 64-Bit Server VM, 1.8.0_162\n",
    "Branch master\n",
    "Compiled by user sameera on 2018-02-22T19:24:29Z\n",
    "Revision a0d7949896e70f427e7f3942ff340c9484ff0aab\n",
    "Url git@github.com:sameeragarwal/spark.git\n",
    "Type --help for more information.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Docker\n",
    "\n",
    "`Dockerfile`\n",
    "\n",
    "```\n",
    "FROM jupyter/pyspark-notebook\n",
    "# Install Python requirements\n",
    "COPY requirements.txt /home/jovyan/\n",
    "RUN pip install -r /home/jovyan/requirements.txt\n",
    "# Run the notebook\n",
    "CMD [\"/opt/conda/bin/jupyter\", \"lab\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%file Dockerfile\n",
    "FROM jupyter/pyspark-notebook\n",
    "# Install Python requirements\n",
    "COPY requirements.txt /home/jovyan/\n",
    "RUN pip install -r /home/jovyan/requirements.txt\n",
    "# Run the notebook\n",
    "CMD [\"/opt/conda/bin/jupyter\", \"lab\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting docker-compose.yml\n"
     ]
    }
   ],
   "source": [
    "%%file docker-compose.yml\n",
    "version: '2'\n",
    "services:\n",
    "  pythonspark:\n",
    "    build: .\n",
    "    restart: always\n",
    "    volumes:\n",
    "      - .:/opt/notebooks      \n",
    "    ports:\n",
    "      - \"8888:8888\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the container:\n",
    "\n",
    "```bash\n",
    "jitsejan@dev16:~/itility/pyspark-101$ docker-compose up -d\n",
    "```\n",
    "\n",
    "Verify it is running:\n",
    "\n",
    "```bash\n",
    "jitsejan@dev16:~/itility/pyspark-101$ docker ps\n",
    "CONTAINER ID        IMAGE                    COMMAND                  CREATED             STATUS              PORTS                    NAMES\n",
    "b15f56d30dd2        pyspark101_pythonspark   \"tini -- /opt/conda/â€¦\"   2 minutes ago       Up 2 minutes        0.0.0.0:8888->8888/tcp   pyspark101_pythonspark_1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the logs to get the token to login to the notebooks:\n",
    "\n",
    "```bash\n",
    "jitsejan@dev16:~/itility/pyspark-101$ docker logs b15f\n",
    "[I 14:51:11.924 LabApp] Writing notebook server cookie secret to /home/jovyan/.local/share/jupyter/runtime/notebook_cookie_secret\n",
    "[W 14:51:12.728 LabApp] WARNING: The notebook server is listening on all IP addresses and not using encryption. This is not recommended.\n",
    "[I 14:51:12.762 LabApp] JupyterLab beta preview extension loaded from /opt/conda/lib/python3.6/site-packages/jupyterlab\n",
    "[I 14:51:12.763 LabApp] JupyterLab application directory is /opt/conda/share/jupyter/lab\n",
    "[I 14:51:12.783 LabApp] Serving notebooks from local directory: /home/jovyan\n",
    "[I 14:51:12.784 LabApp] 0 active kernels\n",
    "[I 14:51:12.784 LabApp] The Jupyter Notebook is running at:\n",
    "[I 14:51:12.784 LabApp] http://[all ip addresses on your system]:8888/?token=a4f12535934ed450211701822064f2df258d0957c8b1d117\n",
    "[I 14:51:12.784 LabApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n",
    "[C 14:51:12.785 LabApp]\n",
    "\n",
    "    Copy/paste this URL into your browser when you connect for the first time,\n",
    "    to login with a token:\n",
    "        http://localhost:8888/?token=a4f12535934ed450211701822064f2df258d0957c8b1d117\n",
    "[I 14:53:53.429 LabApp] 302 GET / (213.152.255.97) 1.10ms\n",
    "[I 14:53:53.516 LabApp] 302 GET /lab? (213.152.255.97) 2.09ms\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Highlights\n",
    "Remember there are different options to develop code in Python. \n",
    "\n",
    "* Local\n",
    "* Virtual environment\n",
    "* Docker\n",
    "\n",
    "Apart from the methods mentioned before, you could also choose to work with an advanced IDE such as [PyCharm](https://www.jetbrains.com/pycharm/) or [Eclipse](http://www.pydev.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful links\n",
    "\n",
    "[Managing environments with Conda](https://conda.io/docs/user-guide/tasks/manage-environments.html)\n",
    "\n",
    "[PySpark Docker GitHub](https://github.com/jupyter/docker-stacks/tree/master/pyspark-notebook)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
